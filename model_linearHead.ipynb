{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from torch.optim import AdamW,Adam,SGD\n",
    "from torch.nn.utils import clip_grad_value_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=12, p=1)\n",
    "data_train = ImgDataset('omniglot-py/images_background',n,k,64,transform)\n",
    "data_train = DataLoader(data_train,b,drop_last=True)\n",
    "data_val = ImgDataset('omniglot-py/images_evaluation',n,k,16,transform)\n",
    "data_val = DataLoader(data_val,b,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "clip = 1e-2\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AttenMeta_linearHead(d, dropout,layers,True).to('cuda')\n",
    "#model.input_target.to('cuda')\n",
    "paras = model.parameters()\n",
    "#opt = AdamW(paras,lr = lr,amsgrad=True)\n",
    "#opt = Adam(paras,lr = lr)\n",
    "opt = SGD(paras,lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:1.0947913396156441, val_loss:0.5650018321143256\n",
      "epoch:1, train_loss:0.4017358114153652, val_loss:0.18906085027588737\n",
      "epoch:2, train_loss:0.21622159950814004, val_loss:0.12110351688332027\n",
      "epoch:3, train_loss:0.14241701844385116, val_loss:0.06226181983947754\n",
      "epoch:4, train_loss:0.11106859387482627, val_loss:0.052106790244579315\n",
      "epoch:5, train_loss:0.08856173263768018, val_loss:0.04778070168362723\n",
      "epoch:6, train_loss:0.07022271513686341, val_loss:0.03059788089659479\n",
      "epoch:7, train_loss:0.06205005413394863, val_loss:0.026727262884378433\n",
      "epoch:8, train_loss:0.05433122567453627, val_loss:0.021090687563021977\n",
      "epoch:9, train_loss:0.05059084712953891, val_loss:0.021288653628693685\n"
     ]
    }
   ],
   "source": [
    "\n",
    "opt.zero_grad()\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    model.train()\n",
    "    np.random.seed()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    # Training #\n",
    "    for i,x in enumerate(data_train):\n",
    "        x = x.to('cuda:0')\n",
    "        loss = model(x,True)\n",
    "        loss.backward()\n",
    "        clip_grad_value_(paras,clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    # evaluating #\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for j,data in enumerate(data_val):\n",
    "            x = x.to('cuda:0')\n",
    "            loss = model(x,True)\n",
    "            val_loss += loss.item()      \n",
    "    print('epoch:{}, train_loss:{}, val_loss:{}'.format(epoch,train_loss/i,val_loss/j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for j,data in enumerate(data_val):\n",
    "        x = x.to('cuda:0')\n",
    "        yhat = model(x,False)\n",
    "        acc += torch.sum(yhat.argmax(-1).flatten() == model.y)/b/n\n",
    "print(acc/(j+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10., device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(yhat.argmax(-1).flatten() == model.y)/b/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([192])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.7488, -1.0974, -2.4001, -0.8369, -1.4614, -2.3128],\n",
       "        [-0.8348,  5.9136, -0.4287, -1.4588, -1.0326, -0.9763],\n",
       "        [-1.6675, -0.3194,  6.3355, -1.1945, -0.9635, -0.4417],\n",
       "        ...,\n",
       "        [-1.1314, -1.0027, -1.6710,  5.1420, -0.9656, -0.6826],\n",
       "        [-0.4006, -1.5854, -1.3414, -1.7718,  6.0901, -1.7882],\n",
       "        [-0.7888, -0.7342, -1.7054, -1.4847, -1.2578,  4.7970]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3704, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for j,data in enumerate(data_val):\n",
    "        x = x.to('cuda:0')\n",
    "        yhat = model(x,False)\n",
    "        acc += torch.sum(yhat.argmax(-1).flatten() == model.y)/b/n\n",
    "print(acc/j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.16666666666666666, 1.791759469228055)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/n, -np.log(1/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.9969, -0.9699, -1.0318, -0.3555, -1.4680,  2.9855],\n",
       "        [-5.1179,  0.7265,  0.6895,  0.6566,  0.6806, -2.0669],\n",
       "        [-5.1179,  0.7265,  0.6895,  0.6566,  0.6806, -2.0669],\n",
       "        ...,\n",
       "        [-5.1178,  0.7264,  0.6896,  0.6564,  0.6806, -2.0670],\n",
       "        [-5.1178,  0.7264,  0.6896,  0.6564,  0.6806, -2.0670],\n",
       "        [ 2.9970, -0.9698, -1.0318, -0.3555, -1.4684,  2.9854]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
